# ==========================================================
# ðŸŒŠ Predictive Risk Modeling for Microplastic Pollution
# Data Mining App using Streamlit
# ==========================================================

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score,
    mean_squared_error, r2_score
)

# -------------------------------
# Streamlit App Setup
# -------------------------------
st.set_page_config(page_title="Microplastic Risk Prediction", layout="wide")
st.title("ðŸŒŠ Predictive Risk Modeling for Microplastic Pollution")
st.caption("Upload your dataset to preprocess, model, and validate predictive insights on microplastic pollution risks.")

# -------------------------------
# Upload Dataset
# -------------------------------
uploaded_file = st.file_uploader("ðŸ“‚ Upload your CSV dataset", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.subheader("ðŸ“‹ Raw Dataset Preview")
    st.dataframe(df.head())

    # ==========================================================
    # STEP 1: Data Cleaning
    # ==========================================================
    df = df.drop_duplicates()
    df = df.fillna('')

    # Convert numeric column
    if 'MP_Count (items/individual)' in df.columns:
        df['MP_Count (items/individual)'] = pd.to_numeric(df['MP_Count (items/individual)'], errors='coerce')

    # Encode binary columns
    if 'MP_Presence' in df.columns:
        df['MP_Presence'] = df['MP_Presence'].map({'Yes': 1, 'No': 0})

    # Multi-label feature expansion
    multi_cols = ['MP_Type', 'MP_Structure', 'MP_Color', 'Polymer_Type', 'Dominant_Risk_Type']
    for col in multi_cols:
        if col in df.columns:
            df[col] = df[col].fillna('')
            unique_tokens = set()
            for val in df[col]:
                unique_tokens.update([v.strip() for v in str(val).split(',') if v.strip() != ''])
            for token in unique_tokens:
                df[token] = df[col].apply(lambda x: 1 if token in str(x) else 0)

    # One-hot encode simple categorical columns
    cat_cols = ['Study_Location', 'Site / Sampling_Area', 'Habitat_Type', 'Species_Name']
    cat_cols = [c for c in cat_cols if c in df.columns]
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

    # Drop non-informative columns
    for col in ['Source_Suspected', 'Author']:
        if col in df.columns:
            df = df.drop(columns=[col])

    # Handle missing numeric values
    df = df.fillna(0)

    st.subheader("âœ… Preprocessed Numeric Dataset")
    st.dataframe(df.head())
    st.write("Shape:", df.shape)

    # ==========================================================
    # STEP 2: Feature Selection
    # ==========================================================
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if 'MP_Count (items/individual)' in numeric_cols:
        target = 'MP_Count (items/individual)'
    else:
        target = numeric_cols[-1]  # fallback

    X = df.drop(columns=[target])
    y = df[target]

    # Scale numeric features
    scaler = StandardScaler()
    # Keep only numeric predictors before scaling
X_numeric = X.select_dtypes(include=[np.number])
X_scaled = scaler.fit_transform(X_numeric)

# Preserve column names for reference
X_scaled = pd.DataFrame(X_scaled, columns=X_numeric.columns)


    # ==========================================================
    # STEP 3: Classification (Risk Presence)
    # ==========================================================
    st.subheader("ðŸ§  Classification: Predicting Microplastic Presence")
    if 'MP_Presence' in df.columns:
        X_class = df.drop(columns=['MP_Presence', target])
        y_class = df['MP_Presence']

        X_train, X_test, y_train, y_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)

        clf = RandomForestClassifier(random_state=42)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)

        st.write("**Accuracy:**", round(accuracy_score(y_test, y_pred), 3))
        st.text("Classification Report:")
        st.text(classification_report(y_test, y_pred))

        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        ax.set_title("Confusion Matrix")
        ax.set_xlabel("Predicted")
        ax.set_ylabel("Actual")
        st.pyplot(fig)

        # Cross-validation
        cv_score = cross_val_score(clf, X_class, y_class, cv=5).mean()
        st.write("**Cross-Validation Accuracy:**", round(cv_score, 3))

    # ==========================================================
    # STEP 4: Clustering (Grouping Similar Sites)
    # ==========================================================
    st.subheader("ðŸ“Š Clustering: Grouping Similar Sampling Areas")
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    df['Cluster'] = clusters

    st.write("Cluster Distribution:")
    st.bar_chart(df['Cluster'].value_counts())

    # 2D visualization (first two principal numeric features)
    fig, ax = plt.subplots()
    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap='viridis')
    ax.set_xlabel("Feature 1")
    ax.set_ylabel("Feature 2")
    ax.set_title("K-Means Clustering Visualization")
    st.pyplot(fig)

    # ==========================================================
    # STEP 5: Regression (Predicting MP Count)
    # ==========================================================
    st.subheader("ðŸ“ˆ Regression: Predicting Microplastic Count")
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    st.write("**Mean Squared Error:**", round(mean_squared_error(y_test, y_pred), 3))
    st.write("**RÂ² Score:**", round(r2_score(y_test, y_pred), 3))

    # Scatter plot of actual vs predicted
    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred, alpha=0.7)
    ax.set_xlabel("Actual MP Count")
    ax.set_ylabel("Predicted MP Count")
    ax.set_title("Actual vs Predicted Microplastic Count")
    st.pyplot(fig)

    # ==========================================================
    # STEP 6: Insights Summary
    # ==========================================================
    st.subheader("ðŸ§¾ Summary of Results")
    st.markdown("""
    - **Data Cleaning & Preprocessing:** Handled duplicates, encoded categorical and text features.
    - **Classification:** Predicted presence of microplastics (Yes/No) with measurable accuracy.
    - **Clustering:** Grouped sampling sites with similar microplastic characteristics.
    - **Regression:** Modeled microplastic count using numeric predictors.
    - **Validation:** Used cross-validation and visualization to ensure reliability.

    âœ… *This provides clear, interpretable results for discussion and conclusion chapters.*
    """)

else:
    st.info("Please upload your dataset to begin analysis.")

